"""Hypothesis verification agent for audit tasks."""

from __future__ import annotations

import json
from dataclasses import dataclass, field
from typing import Any, Literal

from langchain_core.language_models import BaseChatModel
from langchain_core.messages import HumanMessage, SystemMessage

from agents.base_agent import AgentResult, BaseSpecialistAgent


@dataclass
class VerificationResult:
    """Result of verifying a single hypothesis."""

    hypothesis_id: str
    verdict: Literal["confirmed", "refuted", "inconclusive"]
    confidence: float  # 0.0 to 1.0
    supporting_evidence: list[str] = field(default_factory=list)
    contradicting_evidence: list[str] = field(default_factory=list)
    reasoning: str = ""
    recommendations: list[str] = field(default_factory=list)

    def to_dict(self) -> dict[str, Any]:
        return {
            "hypothesis_id": self.hypothesis_id,
            "verdict": self.verdict,
            "confidence": self.confidence,
            "supporting_evidence": self.supporting_evidence,
            "contradicting_evidence": self.contradicting_evidence,
            "reasoning": self.reasoning,
            "recommendations": self.recommendations,
        }


class VerifierAgent(BaseSpecialistAgent):
    """
    Specialist agent for verifying hypotheses against evidence and domain knowledge.

    This agent takes hypotheses generated by the HypothesisAgent and systematically
    verifies them by examining evidence and consulting domain knowledge bases.
    """

    SYSTEM_PROMPT = """あなたは監査仮説検証の専門エージェントです。
提示された仮説を証拠とドメイン知識に基づいて検証することが役割です。

検証の原則:
1. 客観的評価: 仮説を支持する証拠と矛盾する証拠の両方を公平に評価
2. 信頼度の定量化: 証拠の質と量に基づいて信頼度を0.0〜1.0で評価
3. 論理的推論: 証拠から結論への論理的なつながりを明示
4. 推奨事項の提示: 検証結果に基づいて次のアクションを提案

検証結果の判定基準:
- confirmed: 十分な証拠により仮説が支持される（信頼度 >= 0.7）
- refuted: 証拠により仮説が否定される（矛盾する証拠が優勢）
- inconclusive: 判断に十分な証拠がない、または証拠が混在

出力形式（JSON）:
{
    "verifications": [
        {
            "hypothesis_id": "H001",
            "verdict": "confirmed|refuted|inconclusive",
            "confidence": 0.0-1.0,
            "supporting_evidence": ["証拠1", "証拠2"],
            "contradicting_evidence": ["矛盾する証拠"],
            "reasoning": "検証の推論過程",
            "recommendations": ["推奨アクション"]
        }
    ],
    "overall_assessment": "全体的な評価",
    "additional_investigation_needed": ["追加調査が必要な領域"]
}"""

    def __init__(
        self,
        model: BaseChatModel,
        max_iterations: int = 3,
    ):
        super().__init__(
            name="hypothesis_verifier",
            model=model,
            description="Verify hypotheses against evidence and domain knowledge",
            max_iterations=max_iterations,
        )

    def run(self, task: str, context: dict[str, Any] | None = None) -> AgentResult:
        """
        Verify hypotheses based on evidence and domain knowledge.

        Args:
            task: Description of the verification task
            context: Should contain 'hypotheses', 'evidence', and optionally 'domain_knowledge'

        Returns:
            AgentResult containing list of VerificationResult objects
        """
        context = context or {}

        if "hypotheses" not in context:
            return AgentResult(
                agent_name=self.name,
                status="failed",
                data=[],
                confidence=0.0,
                reasoning="検証する仮説が提供されていません",
                metadata={"error": "missing_hypotheses"},
            )

        # Build the prompt with context
        prompt_parts = [f"検証タスク: {task}\n"]

        hypotheses_data = context["hypotheses"]
        if isinstance(hypotheses_data, list):
            hypotheses_str = json.dumps(hypotheses_data, ensure_ascii=False, indent=2)
        else:
            hypotheses_str = str(hypotheses_data)
        prompt_parts.append(f"検証対象の仮説:\n{hypotheses_str}\n")

        if "evidence" in context:
            prompt_parts.append(f"利用可能な証拠:\n{context['evidence']}\n")

        if "domain_knowledge" in context:
            prompt_parts.append(f"ドメイン知識:\n{context['domain_knowledge']}\n")

        if "market_data" in context:
            prompt_parts.append(f"市場データ:\n{context['market_data']}\n")

        prompt_parts.append(
            "\n上記の仮説を証拠とドメイン知識に基づいて検証してください。"
            "JSON形式で出力してください。"
        )

        messages = [
            SystemMessage(content=self.SYSTEM_PROMPT),
            HumanMessage(content="\n".join(prompt_parts)),
        ]

        try:
            response = self.model.invoke(messages)
            content = response.content

            # Parse the JSON response
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            result_data = json.loads(content.strip())

            verifications = [
                VerificationResult(
                    hypothesis_id=v.get("hypothesis_id", f"H{i:03d}"),
                    verdict=v.get("verdict", "inconclusive"),
                    confidence=v.get("confidence", 0.5),
                    supporting_evidence=v.get("supporting_evidence", []),
                    contradicting_evidence=v.get("contradicting_evidence", []),
                    reasoning=v.get("reasoning", ""),
                    recommendations=v.get("recommendations", []),
                )
                for i, v in enumerate(result_data.get("verifications", []), 1)
            ]

            # Calculate aggregate confidence
            if verifications:
                avg_confidence = sum(v.confidence for v in verifications) / len(verifications)
                confirmed_count = sum(1 for v in verifications if v.verdict == "confirmed")
            else:
                avg_confidence = 0.0
                confirmed_count = 0

            # Store in memory
            self.add_to_memory({
                "task": task,
                "verifications_count": len(verifications),
                "confirmed_count": confirmed_count,
                "avg_confidence": avg_confidence,
            })

            return AgentResult(
                agent_name=self.name,
                status="success",
                data=[v.to_dict() for v in verifications],
                confidence=avg_confidence,
                reasoning=result_data.get("overall_assessment", ""),
                metadata={
                    "additional_investigation_needed": result_data.get(
                        "additional_investigation_needed", []
                    ),
                    "confirmed_count": confirmed_count,
                    "total_count": len(verifications),
                },
            )

        except json.JSONDecodeError as e:
            return AgentResult(
                agent_name=self.name,
                status="partial",
                data=[],
                confidence=0.2,
                reasoning=f"JSON解析エラー: {e}. 生の応答: {content[:500]}",
                metadata={"error": str(e)},
            )
        except Exception as e:
            return AgentResult(
                agent_name=self.name,
                status="failed",
                data=[],
                confidence=0.0,
                reasoning=f"仮説検証中にエラーが発生: {e}",
                metadata={"error": str(e)},
            )
